# Big-Data-Analysis
COMPANY: CODTECH IT SOLUTIONS

NAME: Vishal Anand

INTERN ID: CT06DG696

DOMAIN: Data Analytics

DURATION: 6 WEEKS

MENTOR: NEELA SANTOSH

ðŸ”¶ Description
For my Codtech IT Solutions Internship Task-1, I worked on Big Data Analysis using PySpark to demonstrate my ability to handle, process, and derive meaningful insights from large-scale datasets efficiently. The objective of this task was to familiarise myself with distributed data processing frameworks like PySpark and understand their applications in real business scenarios.

I began the task by understanding the requirements, which included performing analysis on a large dataset using tools like PySpark or Dask to demonstrate scalability. I chose PySpark due to its wide industry use in handling big data with its powerful cluster computing capabilities built on top of Apache Spark.

The dataset I used was store_sales.csv, containing 7300 records with five columns: date, store, sales, promo, and holiday. I imported this dataset into my PySpark environment on Google Colab, which provided the necessary scalability and computational power for such analysis.

I performed exploratory data analysis (EDA) using various PySpark DataFrame operations. Firstly, I explored the datasetâ€™s schema to understand each columnâ€™s datatype. Then, I calculated the total number of records to confirm data ingestion completeness. I described numerical columns to check for outliers or unexpected null values that could affect analysis accuracy.

One of the key analyses was calculating the total sales per store, which is crucial for identifying top-performing stores in a retail chain and planning strategic business decisions such as inventory distribution, staff allocation, and local marketing focus.

I also compared average sales on promo days versus non-promo days to understand the effectiveness of promotional campaigns. The results indicated that promotional days had higher average sales, proving promotions as an effective marketing strategy to boost revenue.

Further, I analysed total sales on holidays versus non-holidays, revealing consumer behaviour trends during festive seasons. Such insights help businesses plan targeted discounts or stock up popular items in advance, ensuring maximum customer satisfaction and profitability during peak shopping times.

Through this task, I learnt to utilise SparkSession for initiating PySpark, reading large datasets efficiently, and performing groupby operations to aggregate data meaningfully. The practice of writing code in Google Colab also helped me understand scalable cloud-based notebook environments, which are commonly used in data analytics projects in the corporate world.

Overall, this task helped me build a strong foundation in Big Data Processing and Analysis. I realised the importance of frameworks like PySpark in solving business problems that traditional tools like Excel or basic pandas DataFrames cannot handle at scale. The insights derived through this task can be directly applied to real-life business decision-making processes in the retail industry and beyond.

This internship task has strengthened my data analytics skills, improved my ability to interpret results critically, and prepared me for upcoming tasks involving machine learning and big data pipelines. I am grateful to Codtech IT Solutions for providing such a practical and industry-relevant learning experience.
